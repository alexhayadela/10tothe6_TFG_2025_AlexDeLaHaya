{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2779e815",
   "metadata": {},
   "source": [
    "\n",
    "T√∫ dijiste:\n",
    "i have set of features finance tickers modeling, i get after feature creation\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 126939 entries, 0 to 126938\n",
    "Data columns (total 50 columns):\n",
    " #   Column           Non-Null Count   Dtype         \n",
    "---  ------           --------------   -----         \n",
    " 0   ticker           126939 non-null  object        \n",
    " 1   date             126939 non-null  datetime64[ns]\n",
    " 2   open             126939 non-null  float64       \n",
    " 3   high             126939 non-null  float64       \n",
    " 4   low              126939 non-null  float64       \n",
    " 5   close            126939 non-null  float64       \n",
    " 6   volume           126939 non-null  float64       \n",
    " 7   log_ret_1        126909 non-null  float64       \n",
    " 8   log_ret_3        126849 non-null  float64       \n",
    " 9   log_ret_5        126789 non-null  float64       \n",
    " 10  log_ret_10       126639 non-null  float64       \n",
    " 11  log_ret_20       126342 non-null  float64       \n",
    " 12  ret_mean_5       126789 non-null  float64       \n",
    " 13  vol_5            126789 non-null  float64       \n",
    " 14  vol_10           126639 non-null  float64       \n",
    "remove_cols = [\"ticker\",\"date\",\"open\",\"high\",\"low\",\"close\",\"ibx_close\", \"sp_close\", \"vix_close\", \"volume\",\"target\",\"future_log_ret\"]\n",
    "#X = df_final.drop(columns=remove_cols)\n",
    "X = df_final\n",
    "cols = X.columns\n",
    "print(X.shape)\n",
    "print(X.head(20)) \n",
    "print(len(cols), cols)\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\"\"\"\n",
    "cross_cols = [\"ibx_breadth\",\"ibx_breadth_10d\"]\n",
    "X[cross_cols] = X.groupby(df_final[\"date\"])[cross_cols].transform(lambda x: x.fillna(x.median()))\n",
    "micro_cols = X.columns.difference(cross_cols)\n",
    "X[micro_cols] = X[micro_cols].groupby(df_final[\"ticker\"]).apply(lambda x: x.dropna())\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\"\"\"\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "print(X.shape) \n",
    "\n",
    "y = df_final[\"target\"]\n",
    "y = y[mask]\n",
    "\n",
    "i commented drop columns but regardless\n",
    "if i include only micro features i have return a df with 125k entries, if i include macro it bugs out and returns 0 rows, can you help me out\n",
    "\n",
    "def safe_build_features(df_micro:pd.DataFrame, horizon):\n",
    "    df_final = []\n",
    "    \n",
    "    df_micro = df_micro.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    for ticker, df_t in df_micro.groupby(\"ticker\"):\n",
    "        \n",
    "        df_t = micro_features(df_t)\n",
    "        df_t = target_feature(df_t,horizon)\n",
    "        df_t[\"ticker\"] = ticker\n",
    "        \n",
    "        df_final.append(df_t)\n",
    "    df_final = pd.concat(df_final, ignore_index=True)\n",
    "    #df_final = cross_micro_features(df_final)\n",
    "    #df_final = final_features(df_final)\n",
    "    \n",
    "    return df_final\n",
    "(this is micro only)\n",
    "this now later is all approach (fix) maybe you need to inspect the df\n",
    "it contains ohlcv for ibex sp and vix                                 date          open          high  \\\n",
    "count                          15183  15183.000000  15183.000000   \n",
    "mean   2016-01-06 03:52:38.980438784   4266.447517   4295.721353   \n",
    "min              2006-01-02 00:00:00      9.010000      9.310000   \n",
    "25%              2011-01-05 00:00:00     22.634999     23.740000   \n",
    "50%              2016-01-07 00:00:00   2091.750000   2100.719971   \n",
    "75%              2021-01-07 00:00:00   8714.950195   8784.995549   \n",
    "max              2026-02-03 00:00:00  16636.699219  16661.500000   \n",
    "std                              NaN   4533.780332   4564.210852   \n",
    "\n",
    "                low         close        volume  \n",
    "count  15183.000000  15183.000000  1.518300e+04  \n",
    "mean    4232.886322   4265.793228  1.394026e+09  \n",
    "min        8.560000      9.140000  0.000000e+00  \n",
    "25%       21.530001     22.485000  0.000000e+00  \n",
    "50%     2082.929932   2091.689941  1.579190e+08  \n",
    "75%     8639.150391   8712.745605  3.320480e+09  \n",
    "max    16574.099609  16615.800781  1.145623e+10  \n",
    "std     4498.475527   4533.157153  1.980827e+09  \n",
    "volume 0 cause vix no volume, 15183 non nulll entrries for all 3\n",
    "\n",
    "def build_features(df_micro:pd.DataFrame, df_macro:pd.DataFrame, horizon:int) -> pd.DataFrame:\n",
    "    df_final = []\n",
    "    \n",
    "    df_micro = df_micro.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "    df_macro = df_macro.sort_values(\"date\").reset_index(drop=True)\n",
    "    macro = macro_features(df_macro)\n",
    "    for ticker, df_t in df_micro.groupby(\"ticker\"):\n",
    "        \n",
    "        df_t = micro_features(df_t)\n",
    "        df_t = df_t.merge(macro, on=\"date\", how=\"left\")  \n",
    "        df_t = target_feature(df_t,horizon)\n",
    "        df_t[\"ticker\"] = ticker\n",
    "        \n",
    "        df_final.append(df_t)\n",
    "    df_final = pd.concat(df_final, ignore_index=True)\n",
    "    df_final = cross_micro_features(df_final)\n",
    "    #df_final = final_features(df_final)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# FIX TO NANS, compute macro outside\n",
    "\n",
    "def macro_features(df_macro: pd.DataFrame):\n",
    "\n",
    "    assert_columns(df_macro, [\"date\", \"ticker\", \"close\"])\n",
    "\n",
    "    macro = (\n",
    "        df_macro\n",
    "        .set_index([\"date\", \"ticker\"])[\"close\"]\n",
    "        .unstack(\"ticker\")\n",
    "        .rename(columns={\n",
    "            \"^IBEX\": \"ibx_close\",\n",
    "            \"^GSPC\": \"sp_close\",\n",
    "            \"^VIX\": \"vix_close\",\n",
    "        })\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # IBEX\n",
    "    macro[\"ibx_log_ret_1\"] = np.log(macro[\"ibx_close\"] / macro[\"ibx_close\"].shift(1))\n",
    "    macro[\"ibx_vol_10\"] = macro[\"ibx_log_ret_1\"].rolling(10).std()\n",
    "    macro[\"ibx_vol_60\"] = macro[\"ibx_log_ret_1\"].rolling(60).std()\n",
    "    macro[\"ibx_vol_ratio_10_60\"] = macro[\"ibx_vol_10\"] / macro[\"ibx_vol_60\"]\n",
    "\n",
    "\n",
    "    macro[\"sp_log_ret_1\"] = np.log(macro[\"sp_close\"] / macro[\"sp_close\"].shift(1))\n",
    "    macro[\"sp_vol_20\"] = macro[\"sp_log_ret_1\"].rolling(20).std()\n",
    "    macro[\"sp_vol_100\"] = macro[\"sp_log_ret_1\"].rolling(100).std()\n",
    "    macro[\"sp_vol_ratio_20_100\"] = macro[\"sp_vol_20\"] / macro[\"sp_vol_100\"]\n",
    "\n",
    "    macro[\"vix_chg_1\"] = macro[\"vix_close\"].pct_change()\n",
    "    macro[\"vix_chg_z_5\"] = macro[\"vix_chg_1\"] / macro[\"vix_chg_1\"].rolling(5).std()\n",
    "    macro[\"vix_pctile_250\"] = (\n",
    "        macro[\"vix_close\"]\n",
    "        .rolling(250)\n",
    "        .apply(lambda x: (x <= x[-1]).mean(), raw=True)\n",
    "    )\n",
    "    return macro.reset_index()    \n",
    "\"\"\"\n",
    "\n",
    "ChatGPT Plus\n",
    "Yep ‚Äî this is a classic NaN-nuke caused by macro features + a global dropna. Nothing ‚Äúbugs out‚Äù; Pandas is doing exactly what you told it to do üòÖ\n",
    "Let‚Äôs walk through what‚Äôs happening and how to fix it cleanly.\n",
    "\n",
    "What‚Äôs actually killing all rows\n",
    "This line is the executioner:\n",
    "\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "When you add macro features, you introduce systematic NaNs that every row has at least one of.\n",
    "\n",
    "Why micro-only works\n",
    "Micro features:\n",
    "\n",
    "Computed per ticker\n",
    "\n",
    "Rolling windows (5, 10, 20‚Ä¶) only kill the first few rows per ticker\n",
    "\n",
    "After enough history ‚Üí rows become fully non-NaN\n",
    "\n",
    "Result: ~125k valid rows ‚úÖ\n",
    "\n",
    "Why macro makes everything disappear\n",
    "Your macro pipeline does this:\n",
    "\n",
    "macro[\"ibx_vol_10\"]   = rolling(10)\n",
    "macro[\"ibx_vol_60\"]   = rolling(60)\n",
    "macro[\"sp_vol_100\"]   = rolling(100)\n",
    "macro[\"vix_pctile_250\"] = rolling(250)\n",
    "That means:\n",
    "\n",
    "Feature\tFirst valid row\n",
    "ibx_vol_10\tt ‚â• 10\n",
    "ibx_vol_60\tt ‚â• 60\n",
    "sp_vol_100\tt ‚â• 100\n",
    "vix_pctile_250\tt ‚â• 250 üíÄ\n",
    "Now combine that with:\n",
    "\n",
    "df_t = df_t.merge(macro, on=\"date\", how=\"left\")\n",
    "For every ticker, early dates will have NaNs in at least one macro column.\n",
    "\n",
    "Then you do:\n",
    "\n",
    "X.notna().all(axis=1)\n",
    "That means:\n",
    "\n",
    "‚ÄúDrop the row if any single feature is NaN‚Äù\n",
    "\n",
    "‚û°Ô∏è Result: zero rows survive\n",
    "\n",
    "This is the key conceptual mistake\n",
    "‚ùå Treating macro features like micro features during NaN filtering\n",
    "\n",
    "Macro features are:\n",
    "\n",
    "Shared across tickers\n",
    "\n",
    "Naturally sparse at the beginning\n",
    "\n",
    "Should not be filtered per-row the same way\n",
    "\n",
    "Fixes (from safest ‚Üí more aggressive)\n",
    "‚úÖ Fix 1: Drop NaNs before merge, once, on macro only\n",
    "Trim macro to rows where it‚Äôs fully valid:\n",
    "\n",
    "macro = macro_features(df_macro)\n",
    "\n",
    "macro = macro.dropna().reset_index(drop=True)\n",
    "Now macro starts only at t ‚â• 250.\n",
    "\n",
    "When you merge:\n",
    "\n",
    "df_t = df_t.merge(macro, on=\"date\", how=\"inner\")\n",
    "‚úÖ Result:\n",
    "\n",
    "All macro columns fully populated\n",
    "\n",
    "No NaNs introduced by macro\n",
    "\n",
    "Dataset shrinks in time, not to zero\n",
    "\n",
    "This is the recommended approach for factor models.\n",
    "\n",
    "‚úÖ Fix 2: Separate NaN logic (micro vs macro)\n",
    "Instead of:\n",
    "\n",
    "mask = X.notna().all(axis=1)\n",
    "Do:\n",
    "\n",
    "macro_cols = [c for c in X.columns if c.startswith((\"ibx_\", \"sp_\", \"vix_\"))]\n",
    "micro_cols = X.columns.difference(macro_cols)\n",
    "\n",
    "mask = X[micro_cols].notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "This keeps rows even if macro is NaN early on.\n",
    "\n",
    "‚ö†Ô∏è Downside: model sees NaNs in macro unless you fill them.\n",
    "\n",
    "‚úÖ Fix 3: Forward-fill macro (common in practice)\n",
    "Because macro is market-wide:\n",
    "\n",
    "macro = macro_features(df_macro)\n",
    "macro = macro.sort_values(\"date\").ffill()\n",
    "Then merge.\n",
    "\n",
    "This assumes:\n",
    "\n",
    "‚ÄúLatest known macro state applies to all tickers‚Äù\n",
    "\n",
    "Totally reasonable for VIX / SPX / IBEX factors.\n",
    "\n",
    "‚úÖ Fix 4: Compute macro once, never inside ticker loop (you already did üëç)\n",
    "You did this correctly:\n",
    "\n",
    "macro = macro_features(df_macro)\n",
    "Good ‚Äî do not recompute macro per ticker.\n",
    "\n",
    "One more subtle bug to be aware of\n",
    "This line:\n",
    "\n",
    ".rename(columns={\n",
    "    \"^IBEX\": \"ibx_close\",\n",
    "    \"^GSPC\": \"sp_close\",\n",
    "    \"^VIX\": \"vix_close\",\n",
    "})\n",
    "rename() is exact match, not regex.\n",
    "\n",
    "If your tickers are literally \"^IBEX\", you‚Äôre fine.\n",
    "If not, you want:\n",
    "\n",
    "macro.columns = [\"ibx_close\", \"sp_close\", \"vix_close\"]\n",
    "or:\n",
    "\n",
    "macro = macro.rename(columns=dict(zip(macro.columns,\n",
    "                                      [\"ibx_close\",\"sp_close\",\"vix_close\"])))\n",
    "The cleanest final pattern (recommended)\n",
    "macro = macro_features(df_macro).dropna()\n",
    "\n",
    "df_t = (\n",
    "    micro_features(df_t)\n",
    "    .merge(macro, on=\"date\", how=\"inner\")\n",
    ")\n",
    "\n",
    "df_t = target_feature(df_t, horizon)\n",
    "Then later:\n",
    "\n",
    "X = df_final.drop(columns=remove_cols)\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "This will give you:\n",
    "\n",
    "No silent NaN bombs\n",
    "\n",
    "Predictable dataset size\n",
    "\n",
    "Clean factor-style modeling\n",
    "\n",
    "If you want, next we can:\n",
    "\n",
    "Visualize how many rows each macro feature kills üìâ\n",
    "\n",
    "Design a macro warm-up window explicitly\n",
    "\n",
    "Refactor this into a leakage-safe ML pipeline\n",
    "\n",
    "Just tell me where you want to go next.\n",
    "\n",
    "\n",
    "T√∫ dijiste:\n",
    "That means:\n",
    "\n",
    "‚ÄúDrop the row if any single feature is NaN‚Äù\n",
    "\n",
    "‚û°Ô∏è Result: zero rows survive\n",
    "but i have data from 2006, why all erased i understand 250 x ticker buyt no tall\n",
    "macro = macro_features(df_macro)\n",
    "\n",
    "macro = macro.dropna().reset_index(drop=True)\n",
    "df_t = df_t.merge(macro, on=\"date\", how=\"inner\")\n",
    "what is difference with left here\n",
    "# date when api no issues (volume or negative value wise)\n",
    "    df = ticker.history(start=\"2006-01-01\") i  chose this datew in yahoo fiance cvausse eawrlier bugs i prices does this apliy to biex ticker or sp 500 , can i fetch them earlier so this doesnt affect\n",
    "\n",
    "ChatGPT Plus\n",
    "Great questions ‚Äî this confusion is 100% justified. Let‚Äôs slow it down and untangle why ‚Äúdata since 2006‚Äù can still end up as zero rows, and what left vs inner actually changes in your setup.\n",
    "\n",
    "1Ô∏è‚É£ ‚ÄúI have data from 2006 ‚Äî why does 250 rolling not just kill the start?‚Äù\n",
    "Because the problem is not 250 √ó ticker\n",
    "The problem is date alignment across three macro series + rolling windows + merge logic\n",
    "\n",
    "Your macro frame after macro_features\n",
    "After this:\n",
    "\n",
    "macro = (\n",
    "    df_macro\n",
    "    .set_index([\"date\", \"ticker\"])[\"close\"]\n",
    "    .unstack(\"ticker\")\n",
    ")\n",
    "You now have something like:\n",
    "\n",
    "date\tIBEX\tSP500\tVIX\n",
    "2006-01-02\t‚úî\t‚ùå\t‚úî\n",
    "2006-01-03\t‚úî\t‚úî\t‚ùå\n",
    "...\t\t\t\n",
    "üëâ Unstack introduces NaNs whenever one ticker is missing that date\n",
    "\n",
    "This happens because:\n",
    "\n",
    "IBEX, SP500, VIX do not share identical trading calendars\n",
    "\n",
    "VIX especially has gaps and later start dates\n",
    "\n",
    "Yahoo Finance is inconsistent early on\n",
    "\n",
    "So before rolling windows, your macro already has NaNs.\n",
    "\n",
    "2Ô∏è‚É£ Why macro.dropna() can erase everything\n",
    "This line:\n",
    "\n",
    "macro = macro.dropna()\n",
    "means:\n",
    "\n",
    "‚ÄúKeep only dates where IBEX, SP500, VIX AND all rolling features exist‚Äù\n",
    "\n",
    "Now combine:\n",
    "\n",
    "Calendar mismatches\n",
    "\n",
    "rolling(250) on VIX\n",
    "\n",
    "rolling(100) on SP\n",
    "\n",
    "rolling(60) on IBEX\n",
    "\n",
    "üìâ Result: the intersection of all valid dates may be empty\n",
    "\n",
    "That‚Äôs why:\n",
    "\n",
    "Even though each series individually starts ~2006\n",
    "\n",
    "There may be no date where all macro features are valid simultaneously\n",
    "\n",
    "3Ô∏è‚É£ left vs inner ‚Äî what actually changes\n",
    "how=\"left\"\n",
    "df_t.merge(macro, on=\"date\", how=\"left\")\n",
    "Keeps all micro dates\n",
    "\n",
    "Macro columns are NaN where macro unavailable\n",
    "\n",
    "Later:\n",
    "\n",
    "X.notna().all(axis=1)\n",
    "‚Üí üíÄ kills everything\n",
    "\n",
    "how=\"inner\"\n",
    "df_t.merge(macro, on=\"date\", how=\"inner\")\n",
    "Keeps only dates present in both\n",
    "\n",
    "Prevents macro NaNs from appearing\n",
    "\n",
    "But if macro has zero rows, inner join gives zero rows too\n",
    "\n",
    "‚ö†Ô∏è inner is not a fix if macro is already empty.\n",
    "\n",
    "4Ô∏è‚É£ The REAL root cause (important)\n",
    "Your macro features assume:\n",
    "\n",
    "‚ÄúAll macro instruments trade on the same days‚Äù\n",
    "\n",
    "They don‚Äôt.\n",
    "\n",
    "This is the silent killer:\n",
    "\n",
    ".set_index([\"date\", \"ticker\"]).unstack(\"ticker\")\n",
    "5Ô∏è‚É£ Correct way to build macro features (robust)\n",
    "Step 1: build each macro independently\n",
    "def macro_features(df_macro):\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    for ticker, name in {\n",
    "        \"^IBEX\": \"ibx\",\n",
    "        \"^GSPC\": \"sp\",\n",
    "        \"^VIX\": \"vix\"\n",
    "    }.items():\n",
    "\n",
    "        s = (\n",
    "            df_macro[df_macro[\"ticker\"] == ticker]\n",
    "            .sort_values(\"date\")\n",
    "            .set_index(\"date\")[\"close\"]\n",
    "        )\n",
    "\n",
    "        if name == \"ibx\":\n",
    "            ret = np.log(s / s.shift(1))\n",
    "            out[\"ibx_log_ret_1\"] = ret\n",
    "            out[\"ibx_vol_10\"] = ret.rolling(10).std()\n",
    "            out[\"ibx_vol_60\"] = ret.rolling(60).std()\n",
    "            out[\"ibx_vol_ratio_10_60\"] = out[\"ibx_vol_10\"] / out[\"ibx_vol_60\"]\n",
    "\n",
    "        if name == \"sp\":\n",
    "            ret = np.log(s / s.shift(1))\n",
    "            out[\"sp_log_ret_1\"] = ret\n",
    "            out[\"sp_vol_20\"] = ret.rolling(20).std()\n",
    "            out[\"sp_vol_100\"] = ret.rolling(100).std()\n",
    "            out[\"sp_vol_ratio_20_100\"] = out[\"sp_vol_20\"] / out[\"sp_vol_100\"]\n",
    "\n",
    "        if name == \"vix\":\n",
    "            chg = s.pct_change()\n",
    "            out[\"vix_chg_1\"] = chg\n",
    "            out[\"vix_chg_z_5\"] = chg / chg.rolling(5).std()\n",
    "            out[\"vix_pctile_250\"] = (\n",
    "                s.rolling(250)\n",
    "                .apply(lambda x: (x <= x[-1]).mean(), raw=True)\n",
    "            )\n",
    "\n",
    "    macro = pd.concat(out, axis=1)\n",
    "\n",
    "    return macro.reset_index()\n",
    "Why this works\n",
    "Each macro uses its own calendar\n",
    "\n",
    "Pandas aligns on date safely\n",
    "\n",
    "No unstack-induced NaNs\n",
    "\n",
    "Rolling windows behave as expected\n",
    "\n",
    "6Ô∏è‚É£ Should you fetch data earlier than 2006?\n",
    "Short answer: yes, if Yahoo allows it\n",
    "Especially for:\n",
    "\n",
    "VIX percentiles (250 days ‚âà 1 trading year)\n",
    "\n",
    "Long volatility ratios\n",
    "\n",
    "But:\n",
    "\n",
    "Yahoo VIX before ~2004‚Äì2005 is unreliable\n",
    "\n",
    "SP500 is fine back to 1950\n",
    "\n",
    "IBEX is spotty pre-2000\n",
    "\n",
    "Practical rule\n",
    "Fetch:\n",
    "\n",
    "start = \"2000-01-01\"\n",
    "Then later:\n",
    "\n",
    "macro = macro[macro[\"date\"] >= \"2006-01-01\"]\n",
    "This gives rolling features time to ‚Äúwarm up‚Äù.\n",
    "\n",
    "7Ô∏è‚É£ Final mental model (this is the key takeaway)\n",
    "‚ùå Macro ‚â† micro\n",
    "\n",
    "‚ùå Global dropna() is dangerous\n",
    "\n",
    "‚úÖ Macro should be:\n",
    "\n",
    "computed once\n",
    "\n",
    "calendar-aware\n",
    "\n",
    "warmed up\n",
    "\n",
    "merged after it‚Äôs clean\n",
    "\n",
    "If you want next, I can:\n",
    "\n",
    "Show how many dates each macro kills\n",
    "\n",
    "Add diagnostics to catch this early\n",
    "\n",
    "Help you design a proper factor pipeline (very close to what you‚Äôre building)\n",
    "\n",
    "You‚Äôre on the right track ‚Äî this is exactly the kind of bug quants run into early on.\n",
    "\n",
    "\n",
    "T√∫ dijiste:\n",
    "can i fill macro values so intersection not empty\n",
    "\n",
    "ChatGPT Plus\n",
    "Yes ‚Äî you can, and in fact most people do. The key is how you fill them so you don‚Äôt accidentally introduce look-ahead or garbage signals.\n",
    "\n",
    "Let‚Äôs be very concrete and practical.\n",
    "\n",
    "The right way to think about macro filling\n",
    "Macro features are:\n",
    "\n",
    "market-wide\n",
    "\n",
    "slow-moving\n",
    "\n",
    "shared across all tickers\n",
    "\n",
    "So it is totally acceptable to say:\n",
    "\n",
    "‚ÄúOn any stock trading day, the macro state is the latest known macro observation.‚Äù\n",
    "\n",
    "That means forward-fill, not backward-fill.\n",
    "\n",
    "‚úÖ The safest and most common solution: forward-fill\n",
    "Step 1: build macro on its own calendar\n",
    "(using your existing macro_features or the safer version I sent)\n",
    "\n",
    "macro = macro_features(df_macro)\n",
    "macro = macro.sort_values(\"date\")\n",
    "Step 2: forward-fill macro features\n",
    "macro = macro.ffill()\n",
    "This does not leak future information:\n",
    "\n",
    "Each day uses only past macro data\n",
    "\n",
    "Missing days (holidays, mismatched calendars) are handled\n",
    "\n",
    "‚ö†Ô∏è Important: still drop the very beginning\n",
    "Forward-fill won‚Äôt invent values before the first valid observation.\n",
    "\n",
    "So do:\n",
    "\n",
    "macro = macro.dropna().reset_index(drop=True)\n",
    "This only removes:\n",
    "\n",
    "the initial warm-up period (e.g. first 250 trading days)\n",
    "\n",
    "Not your entire dataset.\n",
    "\n",
    "‚úÖ Merge with micro (recommended)\n",
    "df_t = (\n",
    "    micro_features(df_t)\n",
    "    .merge(macro, on=\"date\", how=\"left\")\n",
    ")\n",
    "Now macro columns:\n",
    "\n",
    "always exist after warm-up\n",
    "\n",
    "never randomly NaN inside the sample\n",
    "\n",
    "Later:\n",
    "\n",
    "mask = X.notna().all(axis=1)\n",
    "‚Üí works as expected.\n",
    "\n",
    "Alternative fills (use only if you know why)\n",
    "üîÅ Rolling mean fill (slower signal)\n",
    "macro = macro.fillna(macro.rolling(5).mean())\n",
    "smooths noise\n",
    "\n",
    "delays signal\n",
    "\n",
    "sometimes used for volatility features\n",
    "\n",
    "üö´ Backward fill (usually wrong)\n",
    "macro = macro.bfill()\n",
    "This leaks future info for macro regimes.\n",
    "\n",
    "Don‚Äôt do this unless you intentionally allow leakage (e.g. offline analysis).\n",
    "\n",
    "Diagnostic check (do this once)\n",
    "Before merging:\n",
    "\n",
    "macro.isna().mean().sort_values(ascending=False)\n",
    "You want:\n",
    "\n",
    "~0 after ffill\n",
    "\n",
    "non-zero only at very beginning\n",
    "\n",
    "TL;DR (rules you can rely on)\n",
    "‚úÖ Yes, fill macro values\n",
    "\n",
    "‚úÖ Use forward fill\n",
    "\n",
    "‚úÖ Drop only the warm-up window\n",
    "\n",
    "‚ùå Never global dropna() before fill\n",
    "\n",
    "‚ùå Don‚Äôt backward-fill macro\n",
    "\n",
    "This is exactly how macro factors are handled in production quant pipelines.\n",
    "\n",
    "If you want next:\n",
    "\n",
    "I can help you label which macro features should be fillable\n",
    "\n",
    "Or build a calendar-aligned macro panel\n",
    "\n",
    "Or add assertions so this never silently breaks again\n",
    "\n",
    "Just tell me üëå\n",
    "\n",
    "\n",
    "T√∫ dijiste:\n",
    "date\tsp_close\tibx_close\tvix_close\tibx_log_ret_1\tibx_vol_10\tibx_vol_60\tibx_vol_ratio_10_60\tsp_log_ret_1\tsp_vol_20\tsp_vol_100\tsp_vol_ratio_20_100\tvix_chg_1\tvix_chg_z_5\tvix_pctile_250\n",
    "5032\t2025-07-03\t6279.350098\t14182.900391\t16.379999\t0.009799\t0.008515\tNaN\tNaN\t0.008304\tNaN\tNaN\tNaN\t-0.015625\t-0.875484\tNaN\n",
    "5033\t2025-07-04\tNaN\t13973.000000\tNaN\t-0.014910\t0.010040\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\t0.000000\t0.000000\tNaN\n",
    "5034\t2025-07-07\t6229.979980\t14074.799805\t17.790001\t0.007259\t0.010212\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\t0.086081\t2.062372\tNaN\n",
    "5035\t2025-07-08\t6225.520020\t14079.500000\t16.809999\t0.000334\t0.009243\tNaN\tNaN\t-0.000716\tNaN\tNaN\tNaN\t-0.055087\t-1.059529\tNaN\n",
    "5036\t2025-07-09\t6263.259766\t14254.400391\t15.940000\t0.012346\t0.007928\tNaN\tNaN\t0.006044\tNaN\tNaN\tNaN\n",
    "so two problems, last month ibex info is not there idknow why, but 202507-04 Nan sp colse and vix close \n",
    "and that makes sp_vol_20 and 100 nan for all window\n",
    "\n",
    "ChatGPT Plus\n",
    "Perfect, this table is exactly what we needed ‚Äî it exposes two distinct problems, and they‚Äôre interacting in a nasty way. You‚Äôre not crazy; this is Yahoo + calendar reality biting you.\n",
    "\n",
    "Let‚Äôs separate them cleanly and fix both.\n",
    "\n",
    "üî¥ Problem 1: 2025-07-04 ‚Äî SP & VIX are NaN, IBEX is not\n",
    "That date is the smoking gun:\n",
    "\n",
    "2025-07-04\n",
    "SP500: NaN\n",
    "VIX:   NaN\n",
    "IBEX:  ‚úî\n",
    "Why this happens (this is normal)\n",
    "July 4th = US Independence Day\n",
    "\n",
    "üá∫üá∏ US markets closed ‚Üí no SP500, no VIX\n",
    "\n",
    "üá™üá∏ Spain market open ‚Üí IBEX trades\n",
    "\n",
    "Yahoo Finance returns:\n",
    "\n",
    "no row or NaN for US indices\n",
    "\n",
    "valid IBEX prices\n",
    "\n",
    "So this is not a data bug ‚Äî it‚Äôs a calendar mismatch.\n",
    "\n",
    "üî¥ Problem 2: One NaN kills the whole rolling window\n",
    "Your rolling code:\n",
    "\n",
    "sp_vol_20  = sp_log_ret_1.rolling(20).std()\n",
    "sp_vol_100 = sp_log_ret_1.rolling(100).std()\n",
    "If any NaN is inside the window:\n",
    "‚û°Ô∏è the rolling result is NaN\n",
    "\n",
    "So July 4th causes:\n",
    "\n",
    "sp_log_ret_1 = NaN\n",
    "\n",
    "every 20-day / 100-day window touching it ‚Üí NaN\n",
    "\n",
    "cascade effect for weeks/months\n",
    "\n",
    "That‚Äôs why:\n",
    "\n",
    "‚Äúsp_vol_20 and 100 are NaN for all window‚Äù\n",
    "\n",
    "‚úÖ Correct macro handling (production-grade fix)\n",
    "Rule you want\n",
    "‚ÄúOn non-US trading days, US macro variables should stay at the last known value.‚Äù\n",
    "\n",
    "That means:\n",
    "\n",
    "forward-fill prices\n",
    "\n",
    "then compute returns & rolling stats\n",
    "\n",
    "üß† The key mistake (important)\n",
    "You are currently doing:\n",
    "\n",
    "‚ùå compute returns ‚Üí ‚ùå rolling ‚Üí ‚ùå then fill\n",
    "\n",
    "You must do:\n",
    "\n",
    "‚úÖ fill prices first ‚Üí then compute everything\n",
    "\n",
    "‚úÖ Step-by-step fix (do exactly this)\n",
    "1Ô∏è‚É£ Build a full macro price panel\n",
    "prices = (\n",
    "    df_macro\n",
    "    .pivot(index=\"date\", columns=\"ticker\", values=\"close\")\n",
    "    .sort_index()\n",
    ")\n",
    "2Ô∏è‚É£ Forward-fill prices (THIS IS THE FIX)\n",
    "prices = prices.ffill()\n",
    "Now:\n",
    "\n",
    "July 4th SP = July 3rd SP\n",
    "\n",
    "July 4th VIX = July 3rd VIX\n",
    "\n",
    "No NaNs inside rolling windows\n",
    "\n",
    "3Ô∏è‚É£ Compute macro features from filled prices\n",
    "macro = pd.DataFrame(index=prices.index)\n",
    "\n",
    "# IBEX\n",
    "ibx = prices[\"^IBEX\"]\n",
    "ibx_ret = np.log(ibx / ibx.shift(1))\n",
    "macro[\"ibx_log_ret_1\"] = ibx_ret\n",
    "macro[\"ibx_vol_10\"] = ibx_ret.rolling(10).std()\n",
    "macro[\"ibx_vol_60\"] = ibx_ret.rolling(60).std()\n",
    "macro[\"ibx_vol_ratio_10_60\"] = macro[\"ibx_vol_10\"] / macro[\"ibx_vol_60\"]\n",
    "\n",
    "# SP500\n",
    "sp = prices[\"^GSPC\"]\n",
    "sp_ret = np.log(sp / sp.shift(1))\n",
    "macro[\"sp_log_ret_1\"] = sp_ret\n",
    "macro[\"sp_vol_20\"] = sp_ret.rolling(20).std()\n",
    "macro[\"sp_vol_100\"] = sp_ret.rolling(100).std()\n",
    "macro[\"sp_vol_ratio_20_100\"] = macro[\"sp_vol_20\"] / macro[\"sp_vol_100\"]\n",
    "\n",
    "# VIX\n",
    "vix = prices[\"^VIX\"]\n",
    "vix_chg = vix.pct_change()\n",
    "macro[\"vix_chg_1\"] = vix_chg\n",
    "macro[\"vix_chg_z_5\"] = vix_chg / vix_chg.rolling(5).std()\n",
    "macro[\"vix_pctile_250\"] = (\n",
    "    vix.rolling(250)\n",
    "       .apply(lambda x: (x <= x[-1]).mean(), raw=True)\n",
    ")\n",
    "\n",
    "macro = macro.reset_index()\n",
    "4Ô∏è‚É£ What this fixes (explicitly)\n",
    "Issue\tStatus\n",
    "US holidays\t‚úÖ handled\n",
    "Calendar mismatch\t‚úÖ handled\n",
    "Rolling NaN cascades\t‚úÖ fixed\n",
    "sp_vol_20 / 100\t‚úÖ stable\n",
    "Macro intersection empty\t‚úÖ impossible\n",
    "üü° About ‚ÄúIBEX info missing last month‚Äù\n",
    "If you see entire blocks missing, check:\n",
    "\n",
    "prices[\"^IBEX\"].isna().sum()\n",
    "prices[\"^IBEX\"].last_valid_index()\n",
    "Yahoo occasionally:\n",
    "\n",
    "delays European indices\n",
    "\n",
    "shifts ticker symbol (^IBEX vs ^IBEX35)\n",
    "\n",
    "returns partial recent data\n",
    "\n",
    "If IBEX is delayed:\n",
    "‚û°Ô∏è forward-fill still keeps macro stable\n",
    "‚û°Ô∏è but you should log it\n",
    "\n",
    "üß™ Sanity checks you should add (highly recommended)\n",
    "assert not prices.isna().any().any(), \"NaNs remain in macro prices\"\n",
    "assert macro.isna().mean().max() < 0.05, \"Too many NaNs in macro features\"\n",
    "These will save you hours later.\n",
    "\n",
    "TL;DR (burn this into memory)\n",
    "US holidays ‚â† EU holidays\n",
    "\n",
    "Always ffill macro prices BEFORE returns\n",
    "\n",
    "Rolling stats die from a single NaN\n",
    "\n",
    "What you‚Äôre seeing is expected, not a bug\n",
    "\n",
    "If you want next, I can:\n",
    "\n",
    "Make this a reusable MacroBuilder class\n",
    "\n",
    "Help you decide which macro features should not be filled\n",
    "\n",
    "Add leakage tests around this\n",
    "\n",
    "You‚Äôre doing real quant work now ‚Äî these are exactly the dragons everyone hits üêâ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Adjuntar\n",
    "\n",
    "Buscar\n",
    "\n",
    "Estudiemos\n",
    "\n",
    "Crear imagen\n",
    "\n",
    "Voz\n",
    "Usamos cookies\n",
    "\n",
    "Usamos cookies para que este sitio funcione, entender el uso del servicio y apoyar los esfuerzos de marketing. Visita la secci√≥n de gesti√≥n de cookies para cambiar tus preferencias en cualquier momento. Consulta nuestra pol√≠tica de cookies para obtener m√°s informaci√≥n.\n",
    "\n",
    "\n",
    "Gestionar cookies\n",
    "\n",
    "Rechazar las que no son esenciales\n",
    "\n",
    "Aceptar todas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc798ab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
