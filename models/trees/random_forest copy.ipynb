{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "from ingest.ohlcv.queries import load_ohlcv\n",
    "from ingest.ohlcv.utils import get_ibex_tickers, get_macro_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3d1ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_ibex_tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m micro = \u001b[43mget_ibex_tickers\u001b[49m()\n\u001b[32m      2\u001b[39m micro_df = load_ohlcv(micro)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Some days have 0 volume e.g on Christmas (API errors)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_ibex_tickers' is not defined"
     ]
    }
   ],
   "source": [
    "micro = get_ibex_tickers()\n",
    "micro_df = load_ohlcv(micro)\n",
    "# Some days have 0 volume e.g on Christmas (API errors)\n",
    "micro_df = micro_df[micro_df[\"volume\"] > 0]\n",
    "print(micro_df.head(1))\n",
    "\n",
    "macro = get_macro_tickers()\n",
    "macro_df = load_ohlcv(macro)\n",
    "print(micro_df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4fc73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_slope(series, window):\n",
    "    x = np.arange(window)\n",
    "    return series.rolling(window).apply(\n",
    "        lambda y: np.polyfit(x, y, 1)[0],\n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "def rsi(series, window):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(window).mean()\n",
    "    avg_loss = loss.rolling(window).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ec73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_micro_features(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Intra ticker features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Returns \n",
    "    df[\"log_ret_1\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "\n",
    "    for w in [3, 5, 10, 20]:\n",
    "        df[f\"log_ret_{w}\"] = np.log(df[\"close\"] / df[\"close\"].shift(w))\n",
    "        # df[f\"ret_mean_{w}\"] = df[\"log_ret_1\"].rolling(w).mean() too correlated with above!\n",
    "    df[\"ret_mean_5\"] = df[\"log_ret_1\"].rolling(5).mean()\n",
    "    # Volatility\n",
    "    for w in [5, 10, 20]:\n",
    "        df[f\"vol_{w}\"] = df[\"log_ret_1\"].rolling(w).std()\n",
    "\n",
    "    # volatility ratios (regime indicators)\n",
    "    df[\"vol_ratio_5_20\"] = df[\"vol_5\"] / df[\"vol_20\"]\n",
    "\n",
    "    # ATR (Average True Range)\n",
    "    high_low = df[\"high\"] - df[\"low\"]\n",
    "    high_close = np.abs(df[\"high\"] - df[\"close\"].shift(1))\n",
    "    low_close = np.abs(df[\"low\"] - df[\"close\"].shift(1))\n",
    "\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df[\"atr_14\"] = true_range.rolling(14).mean()\n",
    "    df[\"atr_pct\"] = df[\"atr_14\"] / df[\"close\"]\n",
    "\n",
    "    # TREND & Momentum strength\n",
    "    # Moving averages & ratios\n",
    "    for w in [5, 10, 20, 50]:\n",
    "        df[f\"sma_{w}\"] = df[\"close\"].rolling(w).mean()\n",
    "        df[f\"ema_{w}\"] = df[\"close\"].ewm(span=w, adjust=False).mean()\n",
    "\n",
    "    df[\"sma_ratio_5_20\"] = df[\"sma_5\"] / df[\"sma_20\"] - 1\n",
    "    df[\"sma_ratio_10_50\"] = df[\"sma_10\"] / df[\"sma_50\"] - 1\n",
    "    df[\"ema_ratio_5_20\"] = df[\"ema_5\"] / df[\"ema_20\"] - 1\n",
    "\n",
    "    # Slope \n",
    "    for w in [10, 20]:\n",
    "        df[f\"slope_{w}\"] = rolling_slope(df[\"close\"], w)\n",
    "    \n",
    "    # Distance to extremes\n",
    "    for w in [10, 20]:\n",
    "        df[f\"dist_high_{w}\"] = df[\"close\"] / df[\"high\"].rolling(w).max() - 1\n",
    "        df[f\"dist_low_{w}\"] = df[\"close\"] / df[\"low\"].rolling(w).min() - 1\n",
    "\n",
    "    # Oscillators: RSI\n",
    "    # df[\"rsi_7\"] = rsi(df[\"close\"], 7)\n",
    "    df[\"rsi_14\"] = rsi(df[\"close\"], 14)\n",
    "\n",
    "    # Stochastic oscillator \n",
    "    low_14 = df[\"low\"].rolling(14).min()\n",
    "    high_14 = df[\"high\"].rolling(14).max()\n",
    "    df[\"stoch_k\"] = 100 * (df[\"close\"] - low_14) / (high_14 - low_14)\n",
    "    #df[\"stoch_d\"] = df[\"stoch_k\"].rolling(3).mean()\n",
    "\n",
    "    # williams r\n",
    "    #df[\"williams_r\"] = -100 * (high_14 - df[\"close\"]) / (high_14 - low_14)\n",
    "\n",
    "    # volume liquidity \n",
    "    #df[\"log_volume\"] = np.log(df[\"volume\"])\n",
    "\n",
    "    for w in [5, 20]:\n",
    "        df[f\"volu_mean_{w}\"] = df[\"volume\"].rolling(w).mean()\n",
    "        df[f\"volu_ratio_{w}\"] = df[\"volume\"] / df[f\"volu_mean_{w}\"]\n",
    "\n",
    "    # On-Balance Volume non stationary\n",
    "    # df[\"obv\"] = (np.sign(df[\"log_ret_1\"]).fillna(0) * df[\"volume\"]).cumsum()\n",
    "\n",
    "    # Volume-return interaction\n",
    "    df[\"volu_ret_1\"] = df[\"log_ret_1\"] * df[\"volu_ratio_5\"]\n",
    "\n",
    "    # candle structure (price action) LESS USEFUL FOR HORIZON 7-9\n",
    "    df[\"body\"] = (df[\"close\"] - df[\"open\"]).abs() / df[\"open\"]\n",
    "\n",
    "    df[\"upper_wick\"] = (df[\"high\"] - df[[\"close\", \"open\"]].max(axis=1)) / df[\"open\"]\n",
    "    df[\"lower_wick\"] = (df[[\"close\", \"open\"]].min(axis=1) - df[\"low\"]) / df[\"open\"]\n",
    "\n",
    "    df[\"true_range_pct\"] = true_range / df[\"close\"]\n",
    "    df[\"gap\"] = (df[\"open\"] - df[\"close\"].shift(1)) / df[\"close\"].shift(1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_columns(df: pd.DataFrame, required, name=\"DataFrame\"):\n",
    "    missing = set(required) - set(df.columns)\n",
    "    if missing:\n",
    "        raise AssertionError(\n",
    "            f\"{name} is missing required columns: {sorted(missing)}\"\n",
    "        )\n",
    "\n",
    "def build_macro_features(df: pd.DataFrame, df_macro: pd.DataFrame):\n",
    "\n",
    "    assert_columns(\n",
    "        df,\n",
    "        [\n",
    "            \"date\",\n",
    "            \"log_ret_5\",\n",
    "            \"log_ret_20\",\n",
    "            \"vol_20\",\n",
    "        ],\n",
    "        name=\"df (micro)\"\n",
    "    )\n",
    "\n",
    "    assert_columns(\n",
    "        df_macro,\n",
    "        [\"date\", \"ticker\", \"close\"],\n",
    "        name=\"df_macro\"\n",
    "    )\n",
    "\n",
    "def build_target_feature(df: pd.DataFrame, horizon):\n",
    "\n",
    "    assert_columns(df, [\"close\"], name=\"df (target)\")\n",
    "    assert horizon > 0, \"horizon must be positive\"\n",
    "\n",
    "# before final model matrix\n",
    "\"\"\"\n",
    "assert \"target\" in micro_features.columns\n",
    "assert micro_features[\"target\"].isin([0, 1]).all()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbfd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_macro_features(df: pd.DataFrame, df_macro: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Macro ticker features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    ibex = df_macro[df_macro[\"ticker\"] == \"^IBEX\"]\n",
    "    sp = df_macro[df_macro[\"ticker\"] == \"^GSPC\"]\n",
    "    vix = df_macro[df_macro[\"ticker\"] == \"^VIX\"]\n",
    "    # ALIGN SERIES \n",
    "\n",
    "    df = df.merge(\n",
    "    ibex[[\"date\", \"close\"]].rename(columns={\"close\": \"ibx_close\"}),\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    "    )\n",
    "    \n",
    "    df = df.merge(\n",
    "    sp[[\"date\", \"close\"]].rename(columns={\"close\": \"sp_close\"}),\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    "    )\n",
    "    \n",
    "    df = df.merge(\n",
    "    vix[[\"date\", \"close\"]].rename(columns={\"close\": \"vix_close\"}),\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Drop later !!!\n",
    "    df[f\"ibx_log_ret_1\"] = np.log(df[\"ibx_close\"] / df[\"ibx_close\"].shift(1))\n",
    "    df[f\"sp_log_ret_1\"] = np.log(df[\"sp_close\"] / df[\"sp_close\"].shift(1))\n",
    "    \n",
    "    # Returns \n",
    "    for w in [5, 10, 20]:\n",
    "        df[f\"ibx_log_ret_{w}\"] = np.log(df[\"ibx_close\"] / df[\"ibx_close\"].shift(w))\n",
    "    for w in [20,50]:\n",
    "        df[f\"sp_log_ret_{w}\"] = np.log(df[\"sp_close\"] / df[\"sp_close\"].shift(w))\n",
    "\n",
    "    # Volatility\n",
    "    for w in [10,20,60]:\n",
    "        df[f\"ibx_vol_{w}\"] = df[\"ibx_log_ret_1\"].rolling(w).std()\n",
    "    for w in [20,60,100]:\n",
    "        df[f\"sp_vol_{w}\"] = df[\"sp_log_ret_1\"].rolling(w).std()\n",
    "\n",
    "    # Volatilty ratio\n",
    "    df[\"ibx_vol_ratio_10_60\"] = df[\"ibx_vol_10\"] / df[\"ibx_vol_60\"]\n",
    "    df[\"sp_vol_ratio_20_100\"] = df[\"sp_vol_20\"] / df[\"sp_vol_100\"]\n",
    "    \n",
    "    df[\"vix_chg_1\"] = df[\"vix_close\"].pct_change()\n",
    "    # Shock detector\n",
    "    df[\"vix_chg_z_5\"] = df[\"vix_chg_1\"] / df[\"vix_chg_1\"].rolling(5).std()\n",
    "    \n",
    "    # Medium-term stress regime\n",
    "    df[\"vix_dev_20\"] = (\n",
    "        df[\"vix_close\"] - df[\"vix_close\"].rolling(20).mean()\n",
    "    )\n",
    "\n",
    "    # Long-term volatility regime (stable)\n",
    "    df[\"vix_pctile_250\"] = (\n",
    "        df[\"vix_close\"]\n",
    "        .rolling(250)\n",
    "        .apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1])\n",
    "    )\n",
    "\n",
    "    # Relative to market\n",
    "    df[\"rel_ret_5\"] = df[\"log_ret_5\"] - df[\"ibx_log_ret_5\"]\n",
    "    df[\"rel_ret_20\"] = df[\"log_ret_20\"] - df[\"ibx_log_ret_20\"]\n",
    "    df[\"rel_vol_20\"] = df[\"vol_20\"] / df[\"ibx_vol_20\"]\n",
    "\n",
    "    return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a548b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_feature(df: pd.DataFrame, horizon):\n",
    "        \n",
    "    df[\"future_log_ret\"] = np.log(df[\"close\"].shift(-horizon) / df[\"close\"])\n",
    "    df[\"target\"] = (df[\"future_log_ret\"] > 0).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 7\n",
    "micro_features = []\n",
    "\n",
    "for ticker, g in micro_df.groupby(\"ticker\"):\n",
    "    g = g.sort_values(\"date\").reset_index(drop=True)\n",
    "    \n",
    "    g = build_micro_features(g)\n",
    "    g = build_macro_features(g, macro_df)   \n",
    "    g = build_target_feature(g,HORIZON)\n",
    "    g[\"ticker\"] = ticker\n",
    "    \n",
    "    micro_features.append(g)\n",
    "\n",
    "micro_features = pd.concat(micro_features, ignore_index=True)\n",
    "# add breath\n",
    "breadth = (\n",
    "    micro_features.groupby(\"date\")[\"log_ret_1\"]\n",
    "        .apply(lambda x: (x > 0).mean())\n",
    "        .rename(\"ibx_breadth\")\n",
    ")\n",
    "micro_features = micro_features.merge(\n",
    "    breadth.reset_index(),\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    ")\n",
    "micro_features[\"ibx_breadth_10d\"] = micro_features[\"ibx_breadth\"].rolling(10).mean()\n",
    "\"\"\" \n",
    "KEEP\n",
    "log_ret_1\n",
    "log_ret_3\n",
    "log_ret_5\n",
    "log_ret_10\n",
    "ret_mean_5\n",
    "slope_10\n",
    "slope_20\n",
    "sma_ratio_5_20\n",
    "ema_ratio_5_20\n",
    "vol_5\n",
    "vol_20\n",
    "vol_ratio_5_20\n",
    "atr_pct\n",
    "true_range_pct\n",
    "dist_high_10\n",
    "dist_low_10\n",
    "dist_high_20\n",
    "dist_low_20\n",
    "rsi_14\n",
    "stoch_k\n",
    "volu_ratio_5\n",
    "volu_ratio_20\n",
    "volu_ret_1\n",
    "body\n",
    "upper_wick\n",
    "lower_wick\n",
    "gap\n",
    "\"\"\"\n",
    "\"\"\" \n",
    "DROP\n",
    "atr_14\n",
    "sma_5, sma_10, sma_20, sma_50\n",
    "ema_5, ema_10, ema_20, ema_50\n",
    "log_volume\n",
    "obv\n",
    "williams_r\n",
    "-------------\n",
    "ret_mean_3 (if log_ret_3 kept)\n",
    "vol_10 (if vol_5 & vol_20 kept)\n",
    "stoch_d (k already enough)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\" \n",
    "KEEP MACRO\n",
    "ibx_vol_10\n",
    "ibx_vol_60\n",
    "ibx_vol_ratio_10_60\n",
    "\n",
    "sp_vol_20\n",
    "sp_vol_100\n",
    "sp_vol_ratio_20_100\n",
    "\n",
    "vix_chg_z_5\n",
    "vix_pctile_250\n",
    "\n",
    "rel_ret_5\n",
    "rel_ret_20\n",
    "rel_vol_20\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "DROP MACRO\n",
    "ibx_log_ret_1\n",
    "ibx_log_ret_5\n",
    "ibx_log_ret_10\n",
    "ibx_log_ret_20\n",
    "sp_log_ret_1\n",
    "sp_log_ret_20\n",
    "sp_log_ret_50\n",
    "vix_dev_20\n",
    "\n",
    "raw macro returns = noisy + leak-prone\n",
    "VIX level differences are not scale invariant\n",
    "\"\"\"\n",
    "# Handle Nan / inf -> divisions  (especially from early rows)\n",
    "\"\"\"  \n",
    "Cross-sectional fill\n",
    "X = (\n",
    "    X\n",
    "    .groupby(micro_features[\"date\"])\n",
    "    .transform(lambda x: x.fillna(x.median()))\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "X = micro_features.drop(columns=[\"ticker\", \"date\", \"target\", \"future_log_ret\"])\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "y = micro_features[\"target\"]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12564831",
   "metadata": {},
   "source": [
    "Where RF struggles\n",
    "\n",
    "Averages many deep, independent trees ‚Üí high bias toward the mean\n",
    "\n",
    "Weak at learning small edge signals\n",
    "\n",
    "No notion of ‚Äúfix previous mistakes‚Äù\n",
    "\n",
    "Needs lots of trees to compete ‚Üí slow\n",
    "\n",
    "RF is great when:\n",
    "\n",
    "Signals are strong\n",
    "\n",
    "Features are low-noise\n",
    "\n",
    "You don‚Äôt care about tiny improvements\n",
    "\n",
    "That is not market data üòÖ\n",
    "\n",
    "Why boosting shines\n",
    "\n",
    "Boosting:\n",
    "\n",
    "Fits trees sequentially\n",
    "\n",
    "Each tree focuses on what previous trees missed\n",
    "\n",
    "Naturally captures:\n",
    "\n",
    "non-linear interactions\n",
    "\n",
    "regime effects (vol ‚Üë ‚Üí feature relevance changes)\n",
    "\n",
    "asymmetric responses (down ‚â† up)\n",
    "\n",
    "That‚Äôs why boosting dominates:\n",
    "\n",
    "quant equity signals\n",
    "\n",
    "factor models\n",
    "\n",
    "medium-horizon classification like yours (7d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0904130",
   "metadata": {},
   "source": [
    "0.5 * LightGBM\n",
    "0.3 * CatBoost\n",
    "0.2 * XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20679ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [300, 600],\n",
    "    \"max_depth\": [5, 7, 10],\n",
    "    \"max_features\": [\"sqrt\", 0.5],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "for train_index, test_index in outer_forward_roll:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    search.fit(X_train, y_train) \n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    preds = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROPER IMPLEEMNTION NO TIME DATA LEAKAGE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "H = 7\n",
    "dates = df_feat[\"date\"].sort_values().unique()\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(dates)):\n",
    "    train_dates = dates[train_idx]\n",
    "    test_dates  = dates[test_idx]\n",
    "\n",
    "    # PURGE to avoid horizon leakage\n",
    "    test_dates = test_dates[H:]\n",
    "\n",
    "    train_mask = df_feat[\"date\"].isin(train_dates)\n",
    "    test_mask  = df_feat[\"date\"].isin(test_dates)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    y_train = y[train_mask]\n",
    "    X_test  = X[test_mask]\n",
    "    y_test  = y[test_mask]\n",
    "\n",
    "    print(f\"Fold {fold}:\",\n",
    "          train_dates[0], \"‚Üí\", train_dates[-1],\n",
    "          \"| test:\", test_dates[0], \"‚Üí\", test_dates[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
